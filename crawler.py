# crawler.py
import os
import json
import time
import requests
from typing import Optional, Tuple

# CWA OpenData endpoint (ä¸è¦æŠŠ Authorization å¯«æ­»åœ¨ URL)
CWA_ENDPOINT = "https://opendata.cwa.gov.tw/fileapi/v1/opendataapi/F-A0010-001"
DATA_DIR = "weather_data"


def _get_api_key() -> Optional[str]:
    """
    ä¾åºå˜—è©¦ï¼š
    1) Streamlit secrets: st.secrets["CWA_API_KEY"]
    2) Environment variable: CWA_API_KEY
    """
    # å…ˆå˜—è©¦ Streamlit secretsï¼ˆå³ä½¿ä¸æ˜¯ç”¨ streamlit runï¼Œä¹Ÿå¯èƒ½è®€å¾—åˆ°ï¼‰
    try:
        import streamlit as st  # noqa: F401
        key = st.secrets.get("CWA_API_KEY", None)
        if key:
            return str(key).strip()
    except Exception:
        pass

    # å†å˜—è©¦ç’°å¢ƒè®Šæ•¸
    key = os.getenv("CWA_API_KEY", "").strip()
    return key or None


def fetch_cwa_json(api_key: str, timeout: int = 20, retries: int = 3) -> dict:
    """
    å‘ CWA æŠ“ JSONï¼Œå…§å»ºç°¡å–®é‡è©¦ã€‚
    """
    session = requests.Session()
    last_err = None

    for i in range(retries):
        try:
            r = session.get(
                CWA_ENDPOINT,
                params={
                    "Authorization": api_key,
                    "downloadType": "WEB",
                    "format": "JSON",
                },
                timeout=timeout,
                headers={"User-Agent": "Mozilla/5.0"},
            )
            r.raise_for_status()
            return r.json()
        except Exception as e:
            last_err = e
            # ç°¡å–®é€€é¿
            time.sleep(1 + i)

    raise RuntimeError(f"Error fetching CWA data after {retries} retries: {last_err}")


def save_json(data: dict, data_dir: str = DATA_DIR) -> str:
    os.makedirs(data_dir, exist_ok=True)
    ts = time.strftime("%Y%m%d_%H%M%S")  # âœ… Windows æª”åå®‰å…¨
    filename = os.path.join(data_dir, f"weather_{ts}.json")
    with open(filename, "w", encoding="utf-8") as f:
        json.dump(data, f, ensure_ascii=False, indent=2)
    return filename


def crawl_and_save(api_key: Optional[str] = None, data_dir: str = DATA_DIR) -> Tuple[str, dict]:
    """
    å›å‚³ (æª”æ¡ˆè·¯å¾‘, json)
    """
    api_key = (api_key or _get_api_key() or "").strip()
    if not api_key:
        raise RuntimeError("Missing API key. Please set Streamlit Secrets: CWA_API_KEY")

    data = fetch_cwa_json(api_key=api_key)
    path = save_json(data, data_dir=data_dir)
    return path, data


if __name__ == "__main__":
    print("ğŸŒ Crawling CWA Open Data...")
    try:
        path, _ = crawl_and_save()
        print(f"âœ… Saved: {path}")
    except Exception as e:
        print("âŒ Error:", e)
        raise
